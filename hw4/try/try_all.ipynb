{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eiahb\\AppData\\Local\\conda\\conda\\envs\\env_ml\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import re,jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.word2vec import Word2Vec,LineSentence\n",
    "from progressbar import progressbar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense ,LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_LENGTH=150\n",
    "ROOT=\"D:/work/school/machine learning/hw/hw4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess\n",
    "## jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\eiahb\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.549 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "file_name=ROOT+\"data_set/dict.txt.big\"\n",
    "jieba.load_userdict(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word(\"^^\")\n",
    "jieba.add_word(\"XD\")\n",
    "jieba.add_word(\"= =\")\n",
    "jieba.add_word(\"Á¥Ø‰∫Ü\")\n",
    "jieba.add_word(\"È†ëgame\")\n",
    "jieba.add_word(\">////<\",1000)\n",
    "jieba.add_word(\"„Ñè„Ñè\")\n",
    "jieba.add_word(\"Âéüpo\")\n",
    "jieba.add_word(\"(¬¨_¬¨)Ôæâ'\")\n",
    "jieba.add_word(\"\")\n",
    "jieba.add_word(\"\")\n",
    "jieba.add_word(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw=pd.read_csv(ROOT+\"data_set/train_x.csv\",encoding=\"utf8\",sep='\\n',header=0).loc[:,'id,comment']\n",
    "X_test_raw=pd.read_csv(ROOT+\"data_set/test_x.csv\",encoding=\"utf8\",sep='\\n',header=0).loc[:,'id,comment']\n",
    "y_train_raw=pd.read_csv(ROOT+\"data_set/train_y.csv\",encoding=\"utf8\").set_index('id')\n",
    "answer_sample=pd.read_csv(ROOT+\"data_set/sample_submission.csv\",encoding=\"utf8\").set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def get_X_split(X_raw):\n",
    "    X_split=X_raw.progress_apply(lambda row:\",\".join(row.split(',')[1:]))\n",
    "    return(X_split)\n",
    "\n",
    "def get_X_resub(X_split):\n",
    "    X_resub=X_split.progress_apply(lambda row:re.sub(\"[Bb][0-9]+\",\"myAtSomebodySpecial,\",row),)\n",
    "    X_resub=X_resub.progress_apply(lambda row:re.sub(\"[0-9]+\",\"myNumberSpecial,\",row))\n",
    "    X_resub=X_resub.progress_apply(lambda row:re.sub(\"[.{2,}]+\",\"......\",row ,count=1))\n",
    "    X_resub=X_resub.progress_apply(lambda row:re.sub(\"[\\s]+\",\"\",row))\n",
    "    return(X_resub)\n",
    "\n",
    "def get_X_tokenize(X_resub):\n",
    "    X_tokenize=X_resub.apply(jieba.lcut)\n",
    "    return(X_tokenize)\n",
    "\n",
    "def get_X_filter(X_tokenize):\n",
    "    X_filter=X_tokenize.apply(lambda row:list(filter(lambda word :word not in stopwords,row)))\n",
    "    return(X_filter)\n",
    "\n",
    "def get_X_padding(X_index):\n",
    "    X_padding=pad_sequences(X_train_index,PADDING_LENGTH)\n",
    "    return(X_padding)\n",
    "\n",
    "def get_X_index(corpus):\n",
    "    new_corpus = []\n",
    "    for doc in corpus:\n",
    "        new_doc = []\n",
    "        for word in doc:\n",
    "            try:\n",
    "                new_doc.append(word2idx[word])\n",
    "            except:\n",
    "                new_doc.append(0)\n",
    "        new_corpus.append(new_doc)\n",
    "    return np.array(new_corpus)\n",
    "\n",
    "def get_answer_num():\n",
    "    with open(ROOT+\"answer/answer_number.txt\",\"r\") as p:\n",
    "        NUM=p.read()\n",
    "        \n",
    "    NUM=int(NUM)+1\n",
    "    with open(ROOT+\"answer/answer_number.txt\",\"w\")as p:\n",
    "        p.write(str(NUM))\n",
    "      \n",
    "    return(NUM)\n",
    "\n",
    "def answer_to_csv(): \n",
    "    ans=np.load(ROOT+\"answer/answer.npy\")\n",
    "    sample=pd.read_csv(ROOT+\"data_set/sample_submission.csv\")\n",
    "    sample.label=ans\n",
    "    NUM=get_answer_num()\n",
    "    sample.to_csv(ROOT+\"answer/answer_\"+str(NUM)+\".csv\",index=False)\n",
    "    print(\"the answer is ready at answer\"+str(NUM)+\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120000/120000 [00:00<00:00, 545326.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120000/120000 [00:00<00:00, 379661.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120000/120000 [00:00<00:00, 294771.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120000/120000 [00:00<00:00, 325129.55it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120000/120000 [00:00<00:00, 220133.28it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_split=get_X_split(X_train_raw)\n",
    "X_train_resub=get_X_resub(X_train_split)\n",
    "X_train_tokenize=get_X_tokenize(X_train_resub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=list()\n",
    "with open('../data_set/stop_word.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopwords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append('ÈΩÅ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filter=get_X_filter(X_train_tokenize)#.apply(lambda row:list(filter(lambda word :word not in stopwords,row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train_filter.npy\",X_train_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draw token num hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_lan=X_train_filter.apply(len)\n",
    "x_train_lan=x_train_lan.sort_values()\n",
    "plt.xlim(0,300)\n",
    "plt.hist(x_train_lan,bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train word2vec weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=Word2Vec(X_train_filter,size=400,workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1526, 2800)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences=['‰ªäÂ§©','Êàë',\"ÊÉ≥Ë¶Å\",\"Ë©¶Ë©¶Áúã\",\"Ë®ìÁ∑¥\",\"Êñ∞\",\"ÁöÑ\",\"Ë©ûÂ∫´\"]\n",
    "w2v_model.build_vocab(new_sentences, update=True)\n",
    "w2v_model.train(new_sentences,total_examples=w2v_model.corpus_count,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| | #                                             | 26823 Elapsed Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(w2v_model.wv.vocab.items()) + 1, w2v_model.vector_size))\n",
    "word2idx = {}\n",
    "vocab_list = [(word, w2v_model.wv[word]) for word, _ in w2v_model.wv.vocab.items()]\n",
    "for i, vocab in progressbar(enumerate(vocab_list)):\n",
    "    word, vec = vocab\n",
    "    embedding_matrix[i + 1] = vec\n",
    "    word2idx[word] = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_to_index„ÄÅpadding \n",
    "### prepare X_train„ÄÅy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Áî∞‰∏≠', 'Â§™ÈÉé', 'Á¨ë', 'üòÇ', 'Áü•ÈÅì', 'ÊúâÊ≤íÊúâ', 'üòç', 'üòç', 'Â∞èÊôÇÂÄô', 'Ë∂ÖÊÑõ', 'üòè']\n"
     ]
    }
   ],
   "source": [
    "X_train_filter=np.load(\"X_train_filter.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Shape: (120000, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train_index=get_X_index(X_train_filter)\n",
    "X_train_padding=get_X_padding(X_train_index)\n",
    "X_train=X_train_padding\n",
    "print(\"X_Shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_Shape: (120000, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train=np.array(y_train_raw).reshape(-1,1)\n",
    "print(\"y_Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [00:00<00:00, 547819.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [00:00<00:00, 366883.91it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [00:00<00:00, 296227.00it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [00:00<00:00, 318649.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [00:00<00:00, 215583.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_Shape: (120000, 150)\n"
     ]
    }
   ],
   "source": [
    "X_test_split=get_X_split(X_test_raw)\n",
    "X_test_resub=get_X_resub(X_test_split)\n",
    "X_test_tokenize=get_X_tokenize(X_test_resub)\n",
    "X_test_filter=get_X_filter(X_test_tokenize)\n",
    "\n",
    "np.save(\"X_test_filter.npy\",X_test_filter)\n",
    "X_test_filter=np.load(\"X_test_filter.npy\")\n",
    "\n",
    "X_test_index=get_X_index(X_test_filter)\n",
    "X_test_padding=get_X_padding(X_test_index)\n",
    "X_test=X_test_padding\n",
    "print(\"X_test_Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use embedding_matrix above build embedding layer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                            output_dim=embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 400)         10730000  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               270848    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 11,198,481\n",
      "Trainable params: 468,481\n",
      "Non-trainable params: 10,730,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 108000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "108000/108000 [==============================] - ETA: 41s - loss: 0.6967 - acc: 0.4503 - binary_accuracy: 0.45 - ETA: 26s - loss: 0.6959 - acc: 0.4618 - binary_accuracy: 0.46 - ETA: 21s - loss: 0.6945 - acc: 0.4853 - binary_accuracy: 0.48 - ETA: 18s - loss: 0.6931 - acc: 0.5079 - binary_accuracy: 0.50 - ETA: 16s - loss: 0.6918 - acc: 0.5273 - binary_accuracy: 0.52 - ETA: 15s - loss: 0.6905 - acc: 0.5455 - binary_accuracy: 0.54 - ETA: 14s - loss: 0.6890 - acc: 0.5626 - binary_accuracy: 0.56 - ETA: 13s - loss: 0.6877 - acc: 0.5750 - binary_accuracy: 0.57 - ETA: 12s - loss: 0.6862 - acc: 0.5857 - binary_accuracy: 0.58 - ETA: 11s - loss: 0.6848 - acc: 0.5938 - binary_accuracy: 0.59 - ETA: 11s - loss: 0.6834 - acc: 0.6002 - binary_accuracy: 0.60 - ETA: 10s - loss: 0.6819 - acc: 0.6064 - binary_accuracy: 0.60 - ETA: 9s - loss: 0.6802 - acc: 0.6133 - binary_accuracy: 0.6133 - ETA: 9s - loss: 0.6786 - acc: 0.6193 - binary_accuracy: 0.619 - ETA: 8s - loss: 0.6771 - acc: 0.6235 - binary_accuracy: 0.623 - ETA: 8s - loss: 0.6757 - acc: 0.6266 - binary_accuracy: 0.626 - ETA: 7s - loss: 0.6743 - acc: 0.6291 - binary_accuracy: 0.629 - ETA: 7s - loss: 0.6729 - acc: 0.6319 - binary_accuracy: 0.631 - ETA: 7s - loss: 0.6714 - acc: 0.6346 - binary_accuracy: 0.634 - ETA: 6s - loss: 0.6697 - acc: 0.6376 - binary_accuracy: 0.637 - ETA: 6s - loss: 0.6679 - acc: 0.6402 - binary_accuracy: 0.640 - ETA: 5s - loss: 0.6665 - acc: 0.6418 - binary_accuracy: 0.641 - ETA: 5s - loss: 0.6649 - acc: 0.6435 - binary_accuracy: 0.643 - ETA: 4s - loss: 0.6632 - acc: 0.6452 - binary_accuracy: 0.645 - ETA: 4s - loss: 0.6614 - acc: 0.6473 - binary_accuracy: 0.647 - ETA: 4s - loss: 0.6600 - acc: 0.6483 - binary_accuracy: 0.648 - ETA: 3s - loss: 0.6583 - acc: 0.6501 - binary_accuracy: 0.650 - ETA: 3s - loss: 0.6568 - acc: 0.6512 - binary_accuracy: 0.651 - ETA: 2s - loss: 0.6554 - acc: 0.6519 - binary_accuracy: 0.651 - ETA: 2s - loss: 0.6536 - acc: 0.6529 - binary_accuracy: 0.652 - ETA: 1s - loss: 0.6518 - acc: 0.6542 - binary_accuracy: 0.654 - ETA: 1s - loss: 0.6501 - acc: 0.6556 - binary_accuracy: 0.655 - ETA: 1s - loss: 0.6486 - acc: 0.6562 - binary_accuracy: 0.656 - ETA: 0s - loss: 0.6469 - acc: 0.6573 - binary_accuracy: 0.657 - ETA: 0s - loss: 0.6454 - acc: 0.6584 - binary_accuracy: 0.658 - 15s 139us/step - loss: 0.6438 - acc: 0.6593 - binary_accuracy: 0.6593 - val_loss: 0.5941 - val_acc: 0.6883 - val_binary_accuracy: 0.6883\n",
      "Epoch 2/3\n",
      "108000/108000 [==============================] - ETA: 13s - loss: 0.5935 - acc: 0.6860 - binary_accuracy: 0.68 - ETA: 12s - loss: 0.5907 - acc: 0.6875 - binary_accuracy: 0.68 - ETA: 12s - loss: 0.5911 - acc: 0.6888 - binary_accuracy: 0.68 - ETA: 11s - loss: 0.5911 - acc: 0.6889 - binary_accuracy: 0.68 - ETA: 11s - loss: 0.5890 - acc: 0.6906 - binary_accuracy: 0.69 - ETA: 11s - loss: 0.5876 - acc: 0.6916 - binary_accuracy: 0.69 - ETA: 10s - loss: 0.5869 - acc: 0.6930 - binary_accuracy: 0.69 - ETA: 10s - loss: 0.5879 - acc: 0.6925 - binary_accuracy: 0.69 - ETA: 10s - loss: 0.5896 - acc: 0.6912 - binary_accuracy: 0.69 - ETA: 9s - loss: 0.5885 - acc: 0.6922 - binary_accuracy: 0.6922 - ETA: 9s - loss: 0.5869 - acc: 0.6936 - binary_accuracy: 0.693 - ETA: 8s - loss: 0.5855 - acc: 0.6946 - binary_accuracy: 0.694 - ETA: 8s - loss: 0.5846 - acc: 0.6950 - binary_accuracy: 0.695 - ETA: 8s - loss: 0.5837 - acc: 0.6957 - binary_accuracy: 0.695 - ETA: 7s - loss: 0.5836 - acc: 0.6954 - binary_accuracy: 0.695 - ETA: 7s - loss: 0.5842 - acc: 0.6950 - binary_accuracy: 0.695 - ETA: 7s - loss: 0.5844 - acc: 0.6945 - binary_accuracy: 0.694 - ETA: 6s - loss: 0.5840 - acc: 0.6947 - binary_accuracy: 0.694 - ETA: 6s - loss: 0.5836 - acc: 0.6947 - binary_accuracy: 0.694 - ETA: 5s - loss: 0.5831 - acc: 0.6954 - binary_accuracy: 0.695 - ETA: 5s - loss: 0.5830 - acc: 0.6958 - binary_accuracy: 0.695 - ETA: 5s - loss: 0.5831 - acc: 0.6959 - binary_accuracy: 0.695 - ETA: 4s - loss: 0.5831 - acc: 0.6960 - binary_accuracy: 0.696 - ETA: 4s - loss: 0.5827 - acc: 0.6963 - binary_accuracy: 0.696 - ETA: 4s - loss: 0.5822 - acc: 0.6967 - binary_accuracy: 0.696 - ETA: 3s - loss: 0.5820 - acc: 0.6970 - binary_accuracy: 0.697 - ETA: 3s - loss: 0.5814 - acc: 0.6975 - binary_accuracy: 0.697 - ETA: 2s - loss: 0.5810 - acc: 0.6979 - binary_accuracy: 0.697 - ETA: 2s - loss: 0.5803 - acc: 0.6982 - binary_accuracy: 0.698 - ETA: 2s - loss: 0.5799 - acc: 0.6984 - binary_accuracy: 0.698 - ETA: 1s - loss: 0.5791 - acc: 0.6990 - binary_accuracy: 0.699 - ETA: 1s - loss: 0.5786 - acc: 0.6997 - binary_accuracy: 0.699 - ETA: 1s - loss: 0.5782 - acc: 0.6999 - binary_accuracy: 0.699 - ETA: 0s - loss: 0.5778 - acc: 0.7007 - binary_accuracy: 0.700 - ETA: 0s - loss: 0.5779 - acc: 0.7008 - binary_accuracy: 0.700 - 14s 131us/step - loss: 0.5779 - acc: 0.7007 - binary_accuracy: 0.7007 - val_loss: 0.5715 - val_acc: 0.7073 - val_binary_accuracy: 0.7073\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108000/108000 [==============================] - ETA: 13s - loss: 0.5675 - acc: 0.7127 - binary_accuracy: 0.71 - ETA: 12s - loss: 0.5652 - acc: 0.7130 - binary_accuracy: 0.71 - ETA: 12s - loss: 0.5681 - acc: 0.7098 - binary_accuracy: 0.70 - ETA: 11s - loss: 0.5672 - acc: 0.7098 - binary_accuracy: 0.70 - ETA: 11s - loss: 0.5664 - acc: 0.7111 - binary_accuracy: 0.71 - ETA: 11s - loss: 0.5680 - acc: 0.7117 - binary_accuracy: 0.71 - ETA: 10s - loss: 0.5668 - acc: 0.7122 - binary_accuracy: 0.71 - ETA: 10s - loss: 0.5656 - acc: 0.7117 - binary_accuracy: 0.71 - ETA: 10s - loss: 0.5657 - acc: 0.7123 - binary_accuracy: 0.71 - ETA: 9s - loss: 0.5667 - acc: 0.7108 - binary_accuracy: 0.7108 - ETA: 9s - loss: 0.5659 - acc: 0.7112 - binary_accuracy: 0.711 - ETA: 8s - loss: 0.5656 - acc: 0.7118 - binary_accuracy: 0.711 - ETA: 8s - loss: 0.5655 - acc: 0.7122 - binary_accuracy: 0.712 - ETA: 8s - loss: 0.5655 - acc: 0.7131 - binary_accuracy: 0.713 - ETA: 7s - loss: 0.5650 - acc: 0.7136 - binary_accuracy: 0.713 - ETA: 7s - loss: 0.5654 - acc: 0.7131 - binary_accuracy: 0.713 - ETA: 7s - loss: 0.5643 - acc: 0.7144 - binary_accuracy: 0.714 - ETA: 6s - loss: 0.5635 - acc: 0.7146 - binary_accuracy: 0.714 - ETA: 6s - loss: 0.5632 - acc: 0.7146 - binary_accuracy: 0.714 - ETA: 5s - loss: 0.5632 - acc: 0.7143 - binary_accuracy: 0.714 - ETA: 5s - loss: 0.5637 - acc: 0.7137 - binary_accuracy: 0.713 - ETA: 5s - loss: 0.5639 - acc: 0.7131 - binary_accuracy: 0.713 - ETA: 4s - loss: 0.5639 - acc: 0.7127 - binary_accuracy: 0.712 - ETA: 4s - loss: 0.5637 - acc: 0.7130 - binary_accuracy: 0.713 - ETA: 4s - loss: 0.5640 - acc: 0.7126 - binary_accuracy: 0.712 - ETA: 3s - loss: 0.5641 - acc: 0.7126 - binary_accuracy: 0.712 - ETA: 3s - loss: 0.5639 - acc: 0.7124 - binary_accuracy: 0.712 - ETA: 2s - loss: 0.5633 - acc: 0.7129 - binary_accuracy: 0.712 - ETA: 2s - loss: 0.5625 - acc: 0.7133 - binary_accuracy: 0.713 - ETA: 2s - loss: 0.5620 - acc: 0.7138 - binary_accuracy: 0.713 - ETA: 1s - loss: 0.5623 - acc: 0.7136 - binary_accuracy: 0.713 - ETA: 1s - loss: 0.5619 - acc: 0.7139 - binary_accuracy: 0.713 - ETA: 1s - loss: 0.5620 - acc: 0.7136 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5619 - acc: 0.7137 - binary_accuracy: 0.713 - ETA: 0s - loss: 0.5621 - acc: 0.7136 - binary_accuracy: 0.713 - 14s 131us/step - loss: 0.5622 - acc: 0.7134 - binary_accuracy: 0.7134 - val_loss: 0.5614 - val_acc: 0.7090 - val_binary_accuracy: 0.7090\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(GRU(16)) \n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "adam=Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=3000, epochs=3, validation_split=0.1,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_np=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(ROOT+\"answer/answer.npy\",answer_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the answer is ready at answer3.csv\n"
     ]
    }
   ],
   "source": [
    "answer_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=np.load(ROOT+\"answer/answer.npy\")\n",
    "sample=pd.read_csv(ROOT+\"data_set/sample_submission.csv\")\n",
    "sample.label=ans\n",
    "NUM=get_answer_num()\n",
    "sample.to_csv(ROOT+\"answer/answer_\"+str(NUM)+\".csv\",index=False)\n",
    "print(\"the answer is ready at answer\"+str(NUM)+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
